{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nbformat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change this to the directory containing your notebooks\n",
    "notebook_dir = 'notebook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['notebook_1.ipynb',\n",
       " 'notebook_2.ipynb',\n",
       " 'notebook_3.ipynb',\n",
       " 'notebook_4.ipynb',\n",
       " 'notebook_5.ipynb',\n",
       " 'notebook_6.ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Collect the names of all notebooks in the directory\n",
    "notebook_names = [f for f in os.listdir(notebook_dir) if f.endswith('.ipynb')]\n",
    "notebook_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the titles and descriptions\n",
    "titles_and_descriptions = {}\n",
    "\n",
    "# Iterate over the notebooks\n",
    "for notebook_name in notebook_names:\n",
    "  # Read the notebook file\n",
    "  with open(os.path.join(notebook_dir, notebook_name), 'r') as f:\n",
    "    notebook = nbformat.reads(f.read(), as_version=4)\n",
    "    # print(\"notebook\", notebook)\n",
    "  \n",
    "  # Extract the first markdown cell\n",
    "  markdown_cells = [cell for cell in notebook['cells'] if cell['cell_type'] == 'markdown']\n",
    "  if markdown_cells:\n",
    "    markdown_cell = markdown_cells[0]\n",
    "    # print(\"markdown_cell\", markdown_cell)\n",
    "    \n",
    "    # Extract the title from the markdown cell (assumes it is the first line)\n",
    "    title_match = re.match(r'# (.*)', markdown_cell['source'])\n",
    "    if title_match:\n",
    "      title = title_match.group(1)\n",
    "    else:\n",
    "      title = 'No title found'\n",
    "      \n",
    "    # Extract the description from the markdown cell (assumes it is everything after the first line)\n",
    "    description_match = re.match(r'# (.*)\\n(.*)', markdown_cell['source'], re.DOTALL)\n",
    "    if description_match:\n",
    "      description = description_match.group(2)\n",
    "    else:\n",
    "      description = 'No description found'\n",
    "      \n",
    "    # Add the title and description to the dictionary using the notebook name as the key\n",
    "    titles_and_descriptions[notebook_name] = (title, description)\n",
    "  else:\n",
    "    # If no markdown cell was found, add a placeholder\n",
    "    titles_and_descriptions[notebook_name] = ('No markdown cell found', 'No markdown cell found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if titles_and_descriptions is not None:\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print(\"No\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description_match.group(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description_match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description_match.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Doing diff on resume (docx)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Doing diff on resume (docx)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Doing diff on resume (docx)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_match.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 29), match='# Doing diff on resume (docx)'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attachments': {},\n",
       " 'cell_type': 'markdown',\n",
       " 'metadata': {},\n",
       " 'source': '# Doing diff on resume (docx)\\nCompare two resumes in docx format.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'attachments': {},\n",
       "  'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': '# Doing diff on resume (docx)\\nCompare two resumes in docx format.'},\n",
       " {'attachments': {},\n",
       "  'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': '```\\nconda install -c conda-forge python-docx\\n````'},\n",
       " {'cell_type': 'code',\n",
       "  'execution_count': 1,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': 'import difflib\\nimport docx\\n'},\n",
       " {'cell_type': 'code',\n",
       "  'execution_count': 2,\n",
       "  'metadata': {},\n",
       "  'outputs': [{'data': {'text/plain': \"'Jansen LIN\\\\nâœ‰ linjansen91@gmail.com   âœ† +65 9793 5363   linkedin.com/in/jansen-lin-jx\\\\xa0   github.com/Jansen-Lin\\\\n\\\\nEXECUTIVE SUMMARY\\\\nPurpose-driven and highly motivated, I aspire to bring positive impact to the world through my work, especially in driving sustainability. I have a diverse range of professional experiences encompassing data science (DS), machine learning (ML), artificial intelligence (AI), environmental/civil/chemical engineering & food science. I envision myself applying data science, ML or AI, to obtain useful insights, automate workflows and optimise resource use and benefits for people. \\\\n\\\\nCORE COMPETENCIES\\\\n\\\\nCAREER EXPERIENCE\\\\nAI SINGAPORE (AISG) â€“ Singapore\\\\t â€“ \\\\nAssociate AI Engineer\\\\nCurrently working on a Computer Vision (CV) project with Continentalâ€™s Automotive group sector, to replace human-operated testing processes for Human-Machine-Interface (HMI) screens with an AI-powered workflow.\\\\nDeveloped & deployed a robust 2-stage pipeline comprising object detection model (YOLOX) and layout matching algorithms, able to achieve layout matching accuracy of over 98% on clientâ€™s HMI screens images dataset.\\\\nInnovated & wrote from scratch in python, a layout matching algorithm for detected layouts of HMI screens, able to rival the accuracy achieved by state-of-the-art ML based algorithms (self-supervised learning models).\\\\nDesigned an effective data preprocessing pipeline after a comprehensive Exploratory Data Analysis (EDA) & close communications with clients to ensure proper raw data preparation (e.g. image data labelling & annotations).\\\\nBuilt a trash detection AI prototype (for a mini-project), as a 4-man team, using the YOLOv5 model deployed via AISGâ€™s open-source, modular framework in Python for CV inferencing (PeekingDuck), in just 3 days.\\\\nCompleted an intensive 2 months deep-skilling phase, deep diving into various core areas of AI (supervised learning, unsupervised learning, MLOps, artificial neural network, computer vision, natural language processing).\\\\n\\\\nNATIONAL UNIVERSITY OF SINGAPORE (NUS) â€“ Singapore\\\\t â€“ \\\\nYong Loo Lin School of Medicine, Department of Medicine\\\\nResearch Engineer\\\\nCo-Invented (lead inventor of) a data-based microfluidic system, able to produce healthy, diabetes-friendly and palatable noodles which are texturally and nutritionally customisable based on userâ€™s inputs. This led to the filing and granting of an international patent (WO2021002804A1). Published 2 related reseach papers as 1st and 2nd author.\\\\nCollaborated and communicated new research findings with a multi-disciplinary team comprising members from 4 domains (Medicine, Chemical & Biomolecular Engineering, Food Science & Technology (FST), Public Health).\\\\nSuccessfully scaled-up a typically low-throughput microfluidic system by 14 times the original production rate. Despite equipment constraints, a bench-top system was set up which enabled novel noodles to be produced at multiple full meal servings for human consumption in clinical trials.\\\\nParticipated in a 10-week entrepreneurship programme (Lean LaunchPad Singapore) as the Team Lead to find product-market fit for our invention. Received mentorship from seasoned industry business leaders. Conducted 44 interviews with medical professionals, nutritionists and targeted consumers and completed a Business Model Canvas. \\\\nSupervised 2 batch of undergraduate students on their final year research projects.\\\\n\\\\nLAND TRANSPORT AUTHORITY (LTA) â€“ Singapore\\\\t â€“ \\\\nEnvironmental Section Intern\\\\nReviewed Environmental Impact Assessment (EIA) reports submitted by Environmental consultants to ensure that the environmental considerations are factored into and robust environmental management plans are put in place for the proposed construction projects.\\\\nEnforced compliance to law and regulation of roads and rails construction sites through conducting of site inspections and reporting of good or bad environmental practices to the management.\\\\nLiaised and worked with stakeholders such as the LTA construction engineers and external concrete experts to explore the feasibility of substituting the commonly used â€˜OPCâ€™ concretes with other concrete types of lower carbon footprint for future MRT stations.\\\\nPresented research findings on EIA review checklist and analysis of Vector data (e.g. dengue cases trends) of LTA construction sites to the team, which improved work processes and promote awareness of latest trends and data.\\\\nEDUCATION HISTORY\\\\nNATIONAL UNIVERSITY OF SINGAPORE (NUS)\\\\nMaster of Science (Environmental Engineering)\\\\t â€“ \\\\nModules with programming/DS/ML: Hydroinformatics, Numerical Methods in Mechanics & Environmental Flows.\\\\nLed multiple team projects with diverse international student members towards quality outcomes.\\\\nBachelor of Engineering (Environmental Engineering), Honours\\\\t â€“ \\\\nAwarded Final Year Project (FYP) Research Poster Award for FYP Symposium, 2016.\\\\n\\\\nPROFESSIONAL QUALIFICATIONS & CERTIFICATIONS/COURSES & TRAINING ATTENDED\\\\nChartered AI Engineering (CAIE) Associate â€“ AI Professionals Association\\\\t \\\\nAwarded via Artificial Intelligence Apprenticeship Programme (AIAP) batch #10 at AISG on 7 Nov 2022, for possessing technical competencies and experiences to build deployable AI solutions and put them into production.\\\\nData Analyst with Python Track â€“ DataCamp\\\\t\\\\t \\\\nCompleted 36 hours worth of training on 24 Dec 2022.\\\\n\\\\nMore certifications available on: linkedin.com/in/jansen-lin-jx/details/certifications/\\\\n\\\\nADDITIONAL\\\\nTechnical Skills: Python, R programming, C programming, Matlab, SQL , Microsoft Office, Power BI, Git, Agile, Google Cloud Platform (GCP), Microsoft Azure, Microsoft Azure Machine Learning, Amazon S3, KubeFlow, Docker, Polyaxon, SOLIDWORKS, QGIS, Delft 3D\\\\nLanguage fluency: English (Fluent) , Mandarin Chinese (Fluent)\\\\nInterests: Badminton (Regular Player, Former Recre Club Captain), Singing (Hark Music School, NUS CAC Voices), Bowling (Elites NUSS)\\\\n\\\\n\\\\n\\\\n'\"},\n",
       "    'execution_count': 2,\n",
       "    'metadata': {},\n",
       "    'output_type': 'execute_result'}],\n",
       "  'source': \"# Open the first Word document and extract its text\\ndocument1 = docx.Document(\\n    # 'C:/Users/Jansen-Lin/Desktop/2. Important Desktop Folders/JOBS RELATED/2022-10-30 Pre-AIAP-Graduation Job Search/014/Resume - Jansen Lin.docx'\\n    'C:/Users/Jansen-Lin/Desktop/2. Important Desktop Folders/JOBS RELATED/2022-10-30 Pre-AIAP-Graduation Job Search/Resume_2_data_pure/Resume - Jansen Lin.docx'\\n)\\ntext1 = '\\\\n'.join([paragraph.text for paragraph in document1.paragraphs])\\ntext1\\n\"},\n",
       " {'cell_type': 'code',\n",
       "  'execution_count': 3,\n",
       "  'metadata': {},\n",
       "  'outputs': [{'data': {'text/plain': \"'Jansen LIN\\\\nâœ‰ linjansen91@gmail.com   âœ† +65 9793 5363   linkedin.com/in/jansen-lin-jx\\\\xa0   github.com/Jansen-Lin\\\\n\\\\nEXECUTIVE SUMMARY\\\\nPurpose-driven and highly motivated, I aspire to bring positive impact to the world through my work, especially in driving sustainability. I have a diverse range of professional experiences encompassing data science (DS), machine learning (ML), artificial intelligence (AI), environmental/civil/chemical engineering & food science. I envision myself applying data science, ML or AI, to obtain useful insights, automate workflows and optimise resource use and benefits for people. \\\\n\\\\nCORE COMPETENCIES\\\\n\\\\nCAREER EXPERIENCE\\\\nAI SINGAPORE (AISG) â€“ Singapore\\\\t â€“ \\\\nAssociate AI Engineer\\\\nCurrently working on a Computer Vision (CV) project with Continentalâ€™s Automotive group sector, to replace human-operated testing processes for Human-Machine-Interface (HMI) screens with an AI-powered workflow.\\\\nDeveloped & deployed a robust 2-stage pipeline comprising object detection model (YOLOX) and layout matching algorithms, able to achieve layout matching accuracy of over 98% on clientâ€™s HMI screens images dataset.\\\\nInnovated & wrote from scratch in python, a layout matching algorithm for detected layouts of HMI screens, able to rival the accuracy achieved by state-of-the-art ML based algorithms (self-supervised learning models).\\\\nDesigned an effective data preprocessing pipeline after a comprehensive Exploratory Data Analysis (EDA) & close communications with clients to ensure proper raw data preparation (e.g. image data labelling & annotations).\\\\nBuilt a trash detection AI prototype (for a mini-project), as a 4-man team, using the YOLOv5 model deployed via AISGâ€™s open-source, modular framework in Python for CV inferencing (PeekingDuck), in just 3 days.\\\\nCompleted an intensive 2 months deep-skilling phase, deep diving into various core areas of AI (supervised learning, unsupervised learning, MLOps, artificial neural network, computer vision, natural language processing).\\\\n\\\\nNATIONAL UNIVERSITY OF SINGAPORE (NUS) â€“ Singapore\\\\t â€“ \\\\nYong Loo Lin School of Medicine, Department of Medicine\\\\nResearch Engineer\\\\nCo-Invented (lead inventor of) a data-based microfluidic system, able to produce healthy, diabetes-friendly and palatable noodles which are texturally and nutritionally customisable based on userâ€™s inputs. This led to the filing and granting of an international patent (WO2021002804A1). Published 2 related reseach papers as 1st and 2nd author.\\\\nCollaborated and communicated new research findings with a multi-disciplinary team comprising members from 4 domains (Medicine, Chemical & Biomolecular Engineering, Food Science & Technology (FST), Public Health).\\\\nSuccessfully scaled-up a typically low-throughput microfluidic system by 14 times the original production rate. Despite equipment constraints, a bench-top system was set up which enabled novel noodles to be produced at multiple full meal servings for human consumption in clinical trials.\\\\nParticipated in a 10-week entrepreneurship programme (Lean LaunchPad Singapore) as the Team Lead to find product-market fit for our invention. Received mentorship from seasoned industry business leaders. Conducted 44 interviews with medical professionals, nutritionists and targeted consumers and completed a Business Model Canvas. \\\\nSupervised 2 batch of undergraduate students on their final year research projects.\\\\n\\\\nLAND TRANSPORT AUTHORITY (LTA) â€“ Singapore\\\\t â€“ \\\\nEnvironmental Section Intern\\\\nReviewed Environmental Impact Assessment (EIA) reports submitted by Environmental consultants to ensure that the environmental considerations are factored into and robust environmental management plans are put in place for the proposed construction projects.\\\\nEnforced compliance to law and regulation of roads and rails construction sites through conducting of site inspections and reporting of good or bad environmental practices to the management.\\\\nLiaised and worked with stakeholders such as the LTA construction engineers and external concrete experts to explore the feasibility of substituting the commonly used â€˜OPCâ€™ concretes with other concrete types of lower carbon footprint for future MRT stations.\\\\nPresented research findings on EIA review checklist and analysis of Vector data (e.g. dengue cases trends) of LTA construction sites to the team, which improved work processes and promote awareness of latest trends and data.\\\\nEDUCATION HISTORY\\\\nNATIONAL UNIVERSITY OF SINGAPORE (NUS)\\\\nMaster of Science (Environmental Engineering)\\\\t â€“ \\\\nModules with programming/DS/ML: Hydroinformatics, Numerical Methods in Mechanics & Environmental Flows.\\\\nLed multiple team projects with diverse international student members towards quality outcomes.\\\\nBachelor of Engineering (Environmental Engineering), Honours\\\\t â€“ \\\\nAwarded Final Year Project (FYP) Research Poster Award for FYP Symposium, 2016.\\\\n\\\\nPROFESSIONAL QUALIFICATIONS & CERTIFICATIONS/COURSES & TRAINING ATTENDED\\\\nChartered AI Engineering (CAIE) Associate â€“ AI Professionals Association\\\\t \\\\nAwarded via Artificial Intelligence Apprenticeship Programme (AIAP) batch #10 at AISG on 7 Nov 2022, for possessing technical competencies and experiences to build deployable AI solutions and put them into production.\\\\nData Analyst with Python Track â€“ DataCamp\\\\t\\\\t \\\\nCompleted 36 hours worth of training on 24 Dec 2022.\\\\n\\\\nMore certifications available on: linkedin.com/in/jansen-lin-jx/details/certifications/\\\\n\\\\nADDITIONAL\\\\nTechnical Skills: Python, R programming, C programming, Matlab, SQL , Microsoft Office, Power BI, Git, Agile, Google Cloud Platform (GCP), Microsoft Azure, Microsoft Azure Machine Learning, Amazon S3, KubeFlow, Docker, Polyaxon, SOLIDWORKS, QGIS, Delft 3D\\\\nLanguage fluency: English (Fluent) , Mandarin Chinese (Fluent)\\\\nInterests: Badminton (Regular Player, Former Recre Club Captain), Singing (Hark Music School, NUS CAC Voices), Bowling (Elites NUSS)\\\\n\\\\n\\\\n\\\\n'\"},\n",
       "    'execution_count': 3,\n",
       "    'metadata': {},\n",
       "    'output_type': 'execute_result'}],\n",
       "  'source': \"# Open the second Word document and extract its text\\ndocument2 = docx.Document(\\n    'C:/Users/Jansen-Lin/Desktop/2. Important Desktop Folders/JOBS RELATED/2022-10-30 Pre-AIAP-Graduation Job Search/Resume_1_NCS/Resume - Jansen Lin.docx'\\n)\\ntext2 = '\\\\n'.join([paragraph.text for paragraph in document2.paragraphs])\\ntext2\"},\n",
       " {'cell_type': 'code',\n",
       "  'execution_count': 4,\n",
       "  'metadata': {},\n",
       "  'outputs': [{'data': {'text/plain': '<generator object Differ.compare at 0x000001A353255F90>'},\n",
       "    'execution_count': 4,\n",
       "    'metadata': {},\n",
       "    'output_type': 'execute_result'}],\n",
       "  'source': '# Compare the texts using the difflib library\\ndiff = difflib.Differ().compare(text1.splitlines(), text2.splitlines())\\ndiff'},\n",
       " {'cell_type': 'code',\n",
       "  'execution_count': 5,\n",
       "  'metadata': {},\n",
       "  'outputs': [{'name': 'stdout',\n",
       "    'output_type': 'stream',\n",
       "    'text': '  Jansen LIN\\n  âœ‰ linjansen91@gmail.com   âœ† +65 9793 5363   linkedin.com/in/jansen-lin-jxÂ\\xa0   github.com/Jansen-Lin\\n  \\n  EXECUTIVE SUMMARY\\n  Purpose-driven and highly motivated, I aspire to bring positive impact to the world through my work, especially in driving sustainability. I have a diverse range of professional experiences encompassing data science (DS), machine learning (ML), artificial intelligence (AI), environmental/civil/chemical engineering & food science. I envision myself applying data science, ML or AI, to obtain useful insights, automate workflows and optimise resource use and benefits for people. \\n  \\n  CORE COMPETENCIES\\n  \\n  CAREER EXPERIENCE\\n  AI SINGAPORE (AISG) â€“ Singapore\\t â€“ \\n  Associate AI Engineer\\n  Currently working on a Computer Vision (CV) project with Continentalâ€™s Automotive group sector, to replace human-operated testing processes for Human-Machine-Interface (HMI) screens with an AI-powered workflow.\\n  Developed & deployed a robust 2-stage pipeline comprising object detection model (YOLOX) and layout matching algorithms, able to achieve layout matching accuracy of over 98% on clientâ€™s HMI screens images dataset.\\n  Innovated & wrote from scratch in python, a layout matching algorithm for detected layouts of HMI screens, able to rival the accuracy achieved by state-of-the-art ML based algorithms (self-supervised learning models).\\n  Designed an effective data preprocessing pipeline after a comprehensive Exploratory Data Analysis (EDA) & close communications with clients to ensure proper raw data preparation (e.g. image data labelling & annotations).\\n  Built a trash detection AI prototype (for a mini-project), as a 4-man team, using the YOLOv5 model deployed via AISGâ€™s open-source, modular framework in Python for CV inferencing (PeekingDuck), in just 3 days.\\n  Completed an intensive 2 months deep-skilling phase, deep diving into various core areas of AI (supervised learning, unsupervised learning, MLOps, artificial neural network, computer vision, natural language processing).\\n  \\n  NATIONAL UNIVERSITY OF SINGAPORE (NUS) â€“ Singapore\\t â€“ \\n  Yong Loo Lin School of Medicine, Department of Medicine\\n  Research Engineer\\n  Co-Invented (lead inventor of) a data-based microfluidic system, able to produce healthy, diabetes-friendly and palatable noodles which are texturally and nutritionally customisable based on userâ€™s inputs. This led to the filing and granting of an international patent (WO2021002804A1). Published 2 related reseach papers as 1st and 2nd author.\\n  Collaborated and communicated new research findings with a multi-disciplinary team comprising members from 4 domains (Medicine, Chemical & Biomolecular Engineering, Food Science & Technology (FST), Public Health).\\n  Successfully scaled-up a typically low-throughput microfluidic system by 14 times the original production rate. Despite equipment constraints, a bench-top system was set up which enabled novel noodles to be produced at multiple full meal servings for human consumption in clinical trials.\\n  Participated in a 10-week entrepreneurship programme (Lean LaunchPad Singapore) as the Team Lead to find product-market fit for our invention. Received mentorship from seasoned industry business leaders. Conducted 44 interviews with medical professionals, nutritionists and targeted consumers and completed a Business Model Canvas. \\n  Supervised 2 batch of undergraduate students on their final year research projects.\\n  \\n  LAND TRANSPORT AUTHORITY (LTA) â€“ Singapore\\t â€“ \\n  Environmental Section Intern\\n  Reviewed Environmental Impact Assessment (EIA) reports submitted by Environmental consultants to ensure that the environmental considerations are factored into and robust environmental management plans are put in place for the proposed construction projects.\\n  Enforced compliance to law and regulation of roads and rails construction sites through conducting of site inspections and reporting of good or bad environmental practices to the management.\\n  Liaised and worked with stakeholders such as the LTA construction engineers and external concrete experts to explore the feasibility of substituting the commonly used â€˜OPCâ€™ concretes with other concrete types of lower carbon footprint for future MRT stations.\\n  Presented research findings on EIA review checklist and analysis of Vector data (e.g. dengue cases trends) of LTA construction sites to the team, which improved work processes and promote awareness of latest trends and data.\\n  EDUCATION HISTORY\\n  NATIONAL UNIVERSITY OF SINGAPORE (NUS)\\n  Master of Science (Environmental Engineering)\\t â€“ \\n  Modules with programming/DS/ML: Hydroinformatics, Numerical Methods in Mechanics & Environmental Flows.\\n  Led multiple team projects with diverse international student members towards quality outcomes.\\n  Bachelor of Engineering (Environmental Engineering), Honours\\t â€“ \\n  Awarded Final Year Project (FYP) Research Poster Award for FYP Symposium, 2016.\\n  \\n  PROFESSIONAL QUALIFICATIONS & CERTIFICATIONS/COURSES & TRAINING ATTENDED\\n  Chartered AI Engineering (CAIE) Associate â€“ AI Professionals Association\\t \\n  Awarded via Artificial Intelligence Apprenticeship Programme (AIAP) batch #10 at AISG on 7 Nov 2022, for possessing technical competencies and experiences to build deployable AI solutions and put them into production.\\n  Data Analyst with Python Track â€“ DataCamp\\t\\t \\n  Completed 36 hours worth of training on 24 Dec 2022.\\n  \\n  More certifications available on: linkedin.com/in/jansen-lin-jx/details/certifications/\\n  \\n  ADDITIONAL\\n  Technical Skills: Python, R programming, C programming, Matlab, SQL , Microsoft Office, Power BI, Git, Agile, Google Cloud Platform (GCP), Microsoft Azure, Microsoft Azure Machine Learning, Amazon S3, KubeFlow, Docker, Polyaxon, SOLIDWORKS, QGIS, Delft 3D\\n  Language fluency: English (Fluent) , Mandarin Chinese (Fluent)\\n  Interests: Badminton (Regular Player, Former Recre Club Captain), Singing (Hark Music School, NUS CAC Voices), Bowling (Elites NUSS)\\n  \\n  \\n  \\n'}],\n",
       "  'source': '# Print the differences\\nfor line in diff:\\n    print(line)'},\n",
       " {'cell_type': 'code',\n",
       "  'execution_count': 6,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': \"# import difflib\\n# import docx\\n\\n# # Open the first Word document and extract its text\\n# document1 = docx.Document(\\n#     '../src/2022-10-30 Pre-AIAP-Graduation Job Search/001/Resume - Jansen Lin')\\n# text1 = '\\\\n'.join([paragraph.text for paragraph in document1.paragraphs])\\n\\n# # Open the second Word document and extract its text\\n# document2 = docx.Document('document2.docx')\\n# text2 = '\\\\n'.join([paragraph.text for paragraph in document2.paragraphs])\\n\\n# # Compare the texts using the difflib library\\n# diff = difflib.Differ().compare(text1.splitlines(), text2.splitlines())\\n\\n# # Print the differences\\n# for line in diff:\\n#     print(line)\"}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook.cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook_1.ipynb\n",
      "Resume details generation tool\n",
      "This aims to output resume details from my source details in excel sheet.\n",
      "\n",
      "notebook_2.ipynb\n",
      "Convert Excel table to Markdown syntax\n",
      "Because typing out the markdown code is tough, therefore, I use python to help me generate the markdown syntax.\n",
      "\n",
      "notebook_3.ipynb\n",
      "Time Series Forecasting with XGBoost - Use python and machine learning to predict energy consumption\n",
      "https://www.youtube.com/watch?v=vV12dGe_Fho\n",
      "\n",
      "notebook_4.ipynb\n",
      "Make Your Pandas Code Lightning Fast\n",
      "Speed up slow pandas/python code by 2500x using this simple trick. Face it, your pandas code is slow. Learn how to speed it up! In this video Rob discusses a key trick to making your code faster! Pandas is an essential tool for any python programmer and data scientist. Using the pandas apply function, using vectorized functions, the speed difference can be significant. Write faster python code.\n",
      "\n",
      "notebook_5.ipynb\n",
      "Try out dask\n",
      "To find out what dask can do and have some hands on with codes.\n",
      "\n",
      "notebook_6.ipynb\n",
      "Doing diff on resume (docx)\n",
      "Compare two resumes in docx format.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the titles and descriptions in the order of the notebook names\n",
    "for notebook_name in notebook_names:\n",
    "  title, description = titles_and_descriptions[notebook_name]\n",
    "  print(notebook_name)\n",
    "  print(title)\n",
    "  print(description)\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a831cfbb3de98ce6ab9c871b23d1d16988161c9f19d83b0ffff4cf37458b0f2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
